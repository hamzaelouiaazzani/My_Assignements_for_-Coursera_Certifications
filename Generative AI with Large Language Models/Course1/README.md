# Generative AI with Large Language Models (LLMs)

Welcome to the README of my submission to  the "Generative AI with Large Language Models (LLMs)" certification (one course)! This course is instructed by top Amazon AI experts: Antje Barth, Shelbee Eigenbrode, Mike Chambers, and Chris Fregly. It is offered by DeepLearning.AI via Coursera.

## Overview

- **Instructors:**
- 
  - Antje Barth
  - Shelbee Eigenbrode
  - Mike Chambers
  - Chris Fregly
    
- **Offered by:** DeepLearning.AI
  
- **Course:** [Generative AI with Large Language Models (LLMs)](https://www.coursera.org/learn/generative-ai-with-llms).
  
- **What You'll Learn:**
  1. Gain foundational knowledge, practical skills, and a functional understanding of how generative AI works.
  2. Dive into the latest research on Gen AI to understand how companies are creating value with cutting-edge technology.
  3. Instruction from expert AWS AI practitioners who actively build and deploy AI in business use-cases today.

## Certification Link

You can find my certification for this course [here](https://coursera.org/share/922e88ee77eb6c36e31e22571b3518d2).

## Notebooks

### Lab 1: Dialogue Summarization with Generative AI using Prompt Engineering techniques

- Lab_1_summarize_dialogue.ipynb : generative_ai_course/Lab_1_summarize_dialogue.ipynb
  - Task: Dialogue Summarization
  - Explore how input text affects model output.
  - Perform prompt engineering for task direction.
  - Compare zero shot, one shot, and few shot inferences.

### Lab 2: Fine-tuning Generative AI Model

- Lab_2_fine_tune_generative_ai_model.ipynb : generative_ai_course/Lab_2_fine_tune_generative_ai_model.ipynb
  - Task: Enhanced Dialogue Summarization
  - Fine-tune FLAN-T5 model from Hugging Face.
  - Use full fine-tuning and evaluate with ROUGE metrics.
  - Perform PEFT fine-tuning and evaluate benefits.

### Lab 3: Fine-tune Model to Detoxify Summaries using Reinforcement Learning from Human Feedback (RLHF)

- Lab_3_fine_tune_model_to_detoxify_summaries.ipynb : generative_ai_course/Lab_3_fine_tune_model_to_detoxify_summaries.ipynb
  - Task: Detoxify Summaries
  - Fine-tune FLAN-T5 model to generate less toxic content.
  - Use Facebook's hate speech reward model with Proximal Policy Optimization Reinforcement learning algorithm (PPO).

Note all rights of these notebooks belong to DeepLearning.AI and AWS. These notebook are my submissions to the practical labs of this certification.
