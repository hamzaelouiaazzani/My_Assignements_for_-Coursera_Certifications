{"cells":[{"cell_type":"markdown","id":"ee925359-cef4-4c70-9b96-8d99b0dbcd50","metadata":{},"outputs":[],"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"32c7b8f5-8fa3-4e2f-bc32-a4cf31b7183d","metadata":{},"outputs":[],"source":["\u003ch1\u003ePractice: Neural Networks with One Hidden Layer: Noisy XOR\u003c/h1\u003e\n"]},{"cell_type":"markdown","id":"9f781be0-8655-425f-ac52-5f81a785a22a","metadata":{},"outputs":[],"source":["\u003ch2\u003eObjective\u003c/h2\u003e\u003cp\u003eAfter completing this lab you will be able to:\u003c/p\u003e \n","\u003cul\u003e\u003cli\u003e Create a neural network model with multiple neurons to model a simple function.\u003c/li\u003e\u003c/ul\u003e\n"]},{"cell_type":"markdown","id":"e02f1104-6fca-4f2a-a5a5-cfb0744ec981","metadata":{},"outputs":[],"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\u003cp\u003eIn this lab, you will see how many neurons it takes to classify noisy XOR data with one hidden layer neural network.\u003c/p\u003e\n","\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"#Model\"\u003eNeural Network Module and Training Function\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Makeup_Data\"\u003eMake Some Data\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#One\"\u003eOne Neuron\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Two\"\u003eTwo Neurons\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Three\"\u003eThree Neurons\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003cp\u003eEstimated Time Needed: \u003cstrong\u003e25 min\u003c/strong\u003e\u003c/p\u003e\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"75f0dc80-b34e-48de-9696-650e8fc0354d","metadata":{},"outputs":[],"source":["\u003ch2\u003ePreparation\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"3d211606-7fdf-49cf-a504-a6dbfcb21407","metadata":{},"outputs":[],"source":["We'll need the following libraries\n"]},{"cell_type":"code","id":"a05c5b89-3bc0-4d8d-87b3-a27113b8323f","metadata":{},"outputs":[],"source":["!pip3 install torch torchvision torchaudio"]},{"cell_type":"code","id":"ddbab125-9281-48ff-80de-cae1333e4d1d","metadata":{},"outputs":[],"source":["# Import the libraries we need for this lab\n\n# Allows us to use arrays to manipulate and store data\nimport numpy as np\n# PyTorch Library\nimport torch\n# PyTorch Neural Network\nimport torch.nn as nn\n# Allows us to use activation functions\nimport torch.nn.functional as F\n# Used to graph data and loss curves\nimport matplotlib.pyplot as plt \nfrom matplotlib.colors import ListedColormap\n# Used to help create the dataset and perform mini-batch\nfrom torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","id":"ff5c7c63-b7a4-4955-bbde-7b2304fa99d2","metadata":{},"outputs":[],"source":["Use the following function to plot the data: \n"]},{"cell_type":"code","id":"3f81dc89-040d-405d-9640-7456c89aa050","metadata":{},"outputs":[],"source":["# Plot the data\n\ndef plot_decision_regions_2class(model,data_set):\n    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#00AAFF'])\n    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#00AAFF'])\n    X = data_set.x.numpy()\n    y = data_set.y.numpy()\n    h = .02\n    x_min, x_max = X[:, 0].min() - 0.1 , X[:, 0].max() + 0.1 \n    y_min, y_max = X[:, 1].min() - 0.1 , X[:, 1].max() + 0.1 \n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n    XX = torch.Tensor(np.c_[xx.ravel(), yy.ravel()])\n\n    yhat = np.logical_not((model(XX)[:, 0] \u003e 0.5).numpy()).reshape(xx.shape)\n    plt.pcolormesh(xx, yy, yhat, cmap=cmap_light, shading='auto')\n    plt.plot(X[y[:, 0] == 0, 0], X[y[:, 0] == 0, 1], 'o', label='y=0')\n    plt.plot(X[y[:, 0] == 1, 0], X[y[:, 0] == 1, 1], 'ro', label='y=1')\n    plt.title(\"decision region\")\n    plt.legend()"]},{"cell_type":"markdown","id":"cff8fc7e-a458-4e04-a838-48d8765dc35c","metadata":{},"outputs":[],"source":["Use the following function to calculate accuracy: \n"]},{"cell_type":"code","id":"7b22b432-eaf8-4806-9016-8322fb142b59","metadata":{},"outputs":[],"source":["# Calculate the accuracy\n\ndef accuracy(model, data_set):\n    # Rounds prediction to nearest integer 0 or 1\n    # Checks if prediction matches the actual values and returns accuracy rate\n    return np.mean(data_set.y.view(-1).numpy() == (model(data_set.x)[:, 0] \u003e 0.5).numpy())"]},{"cell_type":"markdown","id":"5e74ef03-35b6-4f70-88af-1b971d6e476e","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"42540632-8878-44a5-bfde-be7609dd8298","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Model\"\u003eNeural Network Module and Training Function\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"1dd27204-bec4-49e3-970b-5d92d0997885","metadata":{},"outputs":[],"source":["Define the neural network module or class: \n"]},{"cell_type":"code","id":"61bf5a75-82e3-4efb-9225-ba0595521aa0","metadata":{},"outputs":[],"source":["# Define the class Net with one hidden layer \n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        # D_in is the input size of the first layer (size of input layer)\n        # H is the outpout size of the first layer and the input size of the second layer (size of hidden layer)\n        # D_out is the output size of the second layer (size of output layer)\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n\n    # Prediction    \n    def forward(self, x):\n        # Puts x through first layer then sigmoid function\n        x = torch.sigmoid(self.linear1(x)) \n        # Puts result of previous line through second layer then sigmoid function\n        x = torch.sigmoid(self.linear2(x))\n        # Output is a number between 0 and 1 due to the sigmoid function. Whichever the output is closer to, 0 or 1, is the class prediction\n        return x"]},{"cell_type":"markdown","id":"a434492f-6c44-4169-9fe8-bb4352704458","metadata":{},"outputs":[],"source":["Define a function to train the model: \n"]},{"cell_type":"code","id":"2c6b0caa-72af-41fa-9270-a2eea5ea2185","metadata":{},"outputs":[],"source":["# Function to Train the Model\n\ndef train(data_set, model, criterion, train_loader, optimizer, epochs=5):\n    # Lists to keep track of cost and accuracy\n    COST = []\n    ACC = []\n    # Number of times we train on the entire dataset\n    for epoch in range(epochs):\n        # Total loss over epoch\n        total=0\n        # For batch in train laoder\n        for x, y in train_loader:\n            # Resets the calculated gradient value, this must be done each time as it accumulates if we do not reset\n            optimizer.zero_grad()\n            # Makes a prediction based on X value\n            yhat = model(x)\n            # Measures the loss between prediction and acutal Y value\n            loss = criterion(yhat, y)\n            # Calculates the gradient value with respect to each weight and bias\n            loss.backward()\n            # Updates the weight and bias according to calculated gradient value\n            optimizer.step()\n            # Cumulates loss \n            total+=loss.item()\n        # Saves cost and accuracy\n        ACC.append(accuracy(model, data_set))\n        COST.append(total)\n        \n    # Prints Cost vs Epoch graph\n    fig, ax1 = plt.subplots()\n    color = 'tab:red'\n    ax1.plot(COST, color=color)\n    ax1.set_xlabel('epoch', color=color)\n    ax1.set_ylabel('total loss', color=color)\n    ax1.tick_params(axis='y', color=color)\n    \n    # Prints Accuracy vs Epoch graph\n    ax2 = ax1.twinx()  \n    color = 'tab:blue'\n    ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n    ax2.plot(ACC, color=color)\n    ax2.tick_params(axis='y', color=color)\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    \n    plt.show()\n\n    return COST"]},{"cell_type":"markdown","id":"cbeae8c7-407f-436f-9d4f-d048d1b40d59","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"0a1aab60-b4f9-4a0f-834d-87d73aea594b","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Makeup_Data\"\u003eMake Some Data\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"b23002d7-286a-42f1-b645-3495ba974308","metadata":{},"outputs":[],"source":["Dataset class:\n"]},{"cell_type":"code","id":"476bfbfc-6d33-4776-94aa-366e5552a437","metadata":{},"outputs":[],"source":["# Define the class XOR_Data\n\nclass XOR_Data(Dataset):\n    \n    # Constructor\n    # N_s is the size of the dataset\n    def __init__(self, N_s=100):\n        # Create a N_s by 2 array for the X values representing the coordinates\n        self.x = torch.zeros((N_s, 2))\n        # Create a N_s by 1 array for the class the X value belongs to\n        self.y = torch.zeros((N_s, 1))\n        # Split the dataset into 4 sections\n        for i in range(N_s // 4):\n            # Create data centered around (0,0) of class 0\n            self.x[i, :] = torch.Tensor([0.0, 0.0]) \n            self.y[i, 0] = torch.Tensor([0.0])\n\n            # Create data centered around (0,1) of class 1\n            self.x[i + N_s // 4, :] = torch.Tensor([0.0, 1.0])\n            self.y[i + N_s // 4, 0] = torch.Tensor([1.0])\n    \n            # Create data centered around (1,0) of class 1\n            self.x[i + N_s // 2, :] = torch.Tensor([1.0, 0.0])\n            self.y[i + N_s // 2, 0] = torch.Tensor([1.0])\n    \n            # Create data centered around (1,1) of class 0\n            self.x[i + 3 * N_s // 4, :] = torch.Tensor([1.0, 1.0])\n            self.y[i + 3 * N_s // 4, 0] = torch.Tensor([0.0])\n\n            # Add some noise to the X values to make them different\n            self.x = self.x + 0.01 * torch.randn((N_s, 2))\n        self.len = N_s\n\n    # Getter\n    def __getitem__(self, index):    \n        return self.x[index],self.y[index]\n    \n    # Get Length\n    def __len__(self):\n        return self.len\n    \n    # Plot the data\n    def plot_stuff(self):\n        plt.plot(self.x[self.y[:, 0] == 0, 0].numpy(), self.x[self.y[:, 0] == 0, 1].numpy(), 'o', label=\"y=0\")\n        plt.plot(self.x[self.y[:, 0] == 1, 0].numpy(), self.x[self.y[:, 0] == 1, 1].numpy(), 'ro', label=\"y=1\")\n        plt.legend()"]},{"cell_type":"markdown","id":"6e8fe49b-31a8-4ebc-8892-91ca5212d921","metadata":{},"outputs":[],"source":["Dataset object:\n"]},{"cell_type":"code","id":"e0a15120-0337-4885-a0c8-95df9a9d3fd0","metadata":{},"outputs":[],"source":["# Create dataset object\n\ndata_set = XOR_Data()\ndata_set.plot_stuff()"]},{"cell_type":"markdown","id":"6b2a953f-3e4e-4df0-bf8d-362847134d40","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"b950ac44-b0bc-4c02-a986-b9f91265e72d","metadata":{},"outputs":[],"source":["\u003ch2 id=\"One\"\u003eOne Neuron\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"8aecc276-4429-4462-9923-0115bb6c3c7c","metadata":{},"outputs":[],"source":["\u003ch3\u003eTry\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"db6da74d-c56f-48fc-9e77-c87b62a331bf","metadata":{},"outputs":[],"source":["Create a neural network \u003ccode\u003emodel\u003c/code\u003e with one neuron in the hidden layer. Then, use the following code to train it:\n"]},{"cell_type":"code","id":"557fb851-3962-4fcf-bbc9-9e5b14fe7607","metadata":{},"outputs":[],"source":["# Practice: create a model with one neuron\n# Type your code here"]},{"cell_type":"markdown","id":"0a9c729b-c0dc-4928-a439-ce5bceb678a8","metadata":{},"outputs":[],"source":["Double-click \u003cb\u003ehere\u003c/b\u003e for the solution.\n","\n","\u003c!-- \n","model = Net(2, 1, 1)\n","--\u003e\n"]},{"cell_type":"code","id":"02e82913-c08a-4d5b-8587-2ae34c9be091","metadata":{},"outputs":[],"source":["# Train the model\n\nlearning_rate = 0.1\n# We create a criterion which will measure loss\ncriterion = nn.BCELoss()\n# Create an optimizer that updates model parameters using the learning rate and gradient\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# Create a Data Loader for the training data with a batch size of 1 \ntrain_loader = DataLoader(dataset=data_set, batch_size=1)\n# Using the training function train the model on 500 epochs\nLOSS12 = train(data_set, model, criterion, train_loader, optimizer, epochs=500)\n# Plot the data with decision boundaries\nplot_decision_regions_2class(model, data_set)"]},{"cell_type":"markdown","id":"25c77b12-eb7f-4052-a19d-a5cc978cbc09","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"aa374c72-7b70-4e35-b30f-59268906a950","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Two\"\u003eTwo Neurons\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"fb004877-bf0c-47af-94f6-eb08a22a55b5","metadata":{},"outputs":[],"source":["\u003ch3\u003eTry\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"49645c42-9f5d-4a53-a870-d1179e965888","metadata":{},"outputs":[],"source":["Create a neural network \u003ccode\u003emodel\u003c/code\u003e with two neurons in the hidden layer. Then, use the following code to train it:\n"]},{"cell_type":"code","id":"12761fe3-be78-4952-93df-34c48b1142b3","metadata":{},"outputs":[],"source":["# Practice: create a model with two neuron\n# Type your code here"]},{"cell_type":"markdown","id":"24c35230-13f6-4235-a074-ceffb762cc05","metadata":{},"outputs":[],"source":["Double-click \u003cb\u003ehere\u003c/b\u003e for the solution.\n","\n","\u003c!-- \n","model = Net(2, 2, 1)\n","--\u003e\n"]},{"cell_type":"code","id":"ec89282b-5578-4325-b0c3-68d7b82367e0","metadata":{},"outputs":[],"source":["# Train the model\n\nlearning_rate = 0.1\n# We create a criterion which will measure loss\ncriterion = nn.BCELoss()\n# Create an optimizer with the model parameters and learning rate\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# Create a Data Loader for the training data with a batch size of 1 \ntrain_loader = DataLoader(dataset=data_set, batch_size=1)\n# Using the training function train the model on 500 epochs\nLOSS12 = train(data_set, model, criterion, train_loader, optimizer, epochs=500)\n# Plot the data with decision boundaries\nplot_decision_regions_2class(model, data_set)"]},{"cell_type":"markdown","id":"fc926cb1-765b-4f48-92d4-650be80f93aa","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"cc22e376-f5a1-4f18-b25a-4c779c91b35d","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Three\"\u003eThree Neurons\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"a1ed6d59-c749-49eb-94bc-1d9b04d54daf","metadata":{},"outputs":[],"source":["\u003ch3\u003eTry\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"ad5ccc64-49bb-4e1a-a9c5-5ffeadd6b1d0","metadata":{},"outputs":[],"source":["Create a neural network \u003ccode\u003emodel\u003c/code\u003e with three neurons in the hidden layer. Then, use the following code to train it:\n"]},{"cell_type":"code","id":"2a602ec3-ab66-499f-b034-0a0fae313be0","metadata":{},"outputs":[],"source":["# Practice: create a model with two neuron\n# Type your code here"]},{"cell_type":"markdown","id":"17a6b6f9-f5fa-4b36-bc85-53ef0d722938","metadata":{},"outputs":[],"source":["Double-click \u003cb\u003ehere\u003c/b\u003e for the solution.\n","\n","\u003c!-- \n","model = Net(2, 3, 1)\n","--\u003e\n"]},{"cell_type":"code","id":"4e6d72c2-4e05-4036-a384-af8d0112facc","metadata":{},"outputs":[],"source":["# Train the model\n\nlearning_rate = 0.1\n# We create a criterion which will measure loss\ncriterion = nn.BCELoss()\n# Create an optimizer with the model parameters and learning rate\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# Create a Data Loader for the training data with a batch size of 1 \ntrain_loader = DataLoader(dataset=data_set, batch_size=1)\n# Using the training function train the model on 500 epochs\nLOSS12 = train(data_set, model, criterion, train_loader, optimizer, epochs=500)\n# Plot the data with decision boundaries\nplot_decision_regions_2class(model, data_set)"]},{"cell_type":"markdown","id":"af5ce048-c90e-4c8e-b11e-c745309dcb97","metadata":{},"outputs":[],"source":["\n","\n","\u003ca href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\u0026context=cpdaas\u0026apps=data_science_experience%2Cwatson_machine_learning\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"b398f36a-cf39-4e4d-8f41-5fc575e1ba04","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"acbb9242-b5e1-4573-8c58-0822b33b531a","metadata":{},"outputs":[],"source":["\u003ch2\u003eAbout the Authors:\u003c/h2\u003e \n","\n","\u003ca href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\"\u003eJoseph Santarcangelo\u003c/a\u003e has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","id":"75756e71-0ebe-4e67-97b8-c03a8ac2b04b","metadata":{},"outputs":[],"source":["Other contributors: \u003ca href=\"https://www.linkedin.com/in/michelleccarey/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\"\u003eMichelle Carey\u003c/a\u003e, \u003ca href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\"\u003eMavis Zhou\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"984b5b77-c4c8-4a79-a6f8-3c703af2c085","metadata":{},"outputs":[],"source":["\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n"]},{"cell_type":"markdown","id":"c914248e-bf29-4795-b700-526412bf995b","metadata":{},"outputs":[],"source":["\u003chr\u003e\n"]},{"cell_type":"markdown","id":"27391927-19ca-495e-aea4-d4921166bd45","metadata":{},"outputs":[],"source":["\n","## \u003ch3 align=\"center\"\u003e © IBM Corporation 2020. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}