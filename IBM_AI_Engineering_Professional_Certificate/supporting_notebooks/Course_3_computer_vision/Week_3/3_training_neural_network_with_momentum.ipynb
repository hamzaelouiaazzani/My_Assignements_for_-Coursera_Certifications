{"cells":[{"cell_type":"markdown","id":"15b36934-5f21-4a59-83e9-a017b13bd28a","metadata":{},"outputs":[],"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"06b3821d-78af-4116-896e-950b97265fcc","metadata":{},"outputs":[],"source":["\u003ch1\u003eTraining A Neural Network with Momentum\u003c/h1\u003e\n"]},{"cell_type":"markdown","id":"ecb81af6-1473-4362-b566-bc2eed4320b2","metadata":{},"outputs":[],"source":["\n","\u003ch3\u003eObjective for this Notebook\u003ch3\u003e    \n","\u003ch5\u003e 1. Train Different Neural Networks Model different values for the Momentum Parameter.\u003c/h5\u003e\n","\u003ch5\u003e 2. Compare Results of Different Momentum Terms. \u003c/h5\u003e     \n","\n"]},{"cell_type":"markdown","id":"cae2a9a1-c136-4f4e-a42d-d32901183bec","metadata":{},"outputs":[],"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\u003cp\u003eIn this lab, you will see how different values for the momentum parameters affect the convergence rate of a neural network.\u003c/p\u003e\n","\n","\u003cul\u003e\n","\u003cli\u003e\u003ca href=\"#Model\"\u003eNeural Network Module and Function for Training\u003c/a\u003e\u003c/li\u003e\n","\u003cli\u003e\u003ca href=\"#Train\"\u003eTrain Different Neural Networks Model different values for the Momentum Parameter\u003c/a\u003e\u003c/li\u003e\n","\u003cli\u003e\u003ca href=\"#Result\"\u003eCompare Results of Different Momentum Terms\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003cp\u003eEstimated Time Needed: \u003cstrong\u003e25 min\u003c/strong\u003e\u003c/p\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"c7c959ba-aae3-47be-b446-30aecf16805d","metadata":{},"outputs":[],"source":["\u003ch2\u003ePreparation\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"a5d02675-cc7a-49a1-b3ae-7892b4521b09","metadata":{},"outputs":[],"source":["We'll need the following libraries:  \n"]},{"cell_type":"code","id":"14a12806-a18c-48ac-9c0a-10be20fe8d32","metadata":{},"outputs":[],"source":["!pip3 install torch torchvision torchaudio"]},{"cell_type":"code","id":"d025a97d-c2e6-4bb9-9086-0c9c59e700ed","metadata":{},"outputs":[],"source":["# Import the libraries for this lab\n\n# Used to graph data and loss curves\nimport matplotlib.pyplot as plt \n# Allows us to use arrays to manipulate and store data\nimport numpy as np\n# PyTorch Library\nimport torch\n# PyTorch Neural Network\nimport torch.nn as nn\n# Allows us to use activation functions\nimport torch.nn.functional as F\n# Used to graph data and loss curves\nfrom matplotlib.colors import ListedColormap\n# Used to help create the dataset and perform mini-batch\nfrom torch.utils.data import Dataset, DataLoader\n\ntorch.manual_seed(1)\nnp.random.seed(1)"]},{"cell_type":"markdown","id":"f4f8180e-324c-4a45-9275-8617d2148c0f","metadata":{},"outputs":[],"source":["Functions used to plot:\n"]},{"cell_type":"code","id":"4abdc669-65cf-409d-b0e4-2eaf42ace1d1","metadata":{},"outputs":[],"source":["# Define a function to plot the decision region\n\ndef plot_decision_regions_3class(model, data_set):\n    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA','#00AAFF'])\n    cmap_bold = ListedColormap(['#FF0000', '#00FF00','#00AAFF'])\n    X=data_set.x.numpy()\n    y=data_set.y.numpy()\n    h = .02\n    x_min, x_max = X[:, 0].min() - 0.1 , X[:, 0].max() + 0.1 \n    y_min, y_max = X[:, 1].min() - 0.1 , X[:, 1].max() + 0.1 \n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n    XX=torch.torch.Tensor(np.c_[xx.ravel(), yy.ravel()])\n    _,yhat=torch.max(model(XX),1)\n    yhat=yhat.numpy().reshape(xx.shape)\n    plt.pcolormesh(xx, yy, yhat, cmap=cmap_light, shading='auto')\n    plt.plot(X[y[:]==0,0], X[y[:]==0,1], 'ro', label='y=0')\n    plt.plot(X[y[:]==1,0], X[y[:]==1,1], 'go', label='y=1')\n    plt.plot(X[y[:]==2,0], X[y[:]==2,1], 'o', label='y=2')\n    plt.title(\"decision region\")\n    plt.legend()"]},{"cell_type":"markdown","id":"8bcb604d-c825-4961-898b-5b7411274016","metadata":{},"outputs":[],"source":["Create the dataset class: We will display the dataset later below\n"]},{"cell_type":"code","id":"0234e4b4-2246-4c81-9389-206d55eaf0ab","metadata":{},"outputs":[],"source":["# Create the dataset class\n\nclass Data(Dataset):\n    \n    # modified from: http://cs231n.github.io/neural-networks-case-study/\n    # Constructor\n    def __init__(self, K=3, N=500):\n        D = 2\n        X = np.zeros((N * K, D)) # data matrix (each row = single example)\n        y = np.zeros(N * K, dtype='uint8') # class labels\n        for j in range(K):\n          ix = range(N * j, N * (j + 1))\n          r = np.linspace(0.0, 1, N) # radius\n          t = np.linspace(j * 4, (j + 1) * 4, N) + np.random.randn(N) * 0.2 # theta\n          X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n          y[ix] = j\n    \n        self.y = torch.from_numpy(y).type(torch.LongTensor)\n        self.x = torch.from_numpy(X).type(torch.FloatTensor)\n        self.len = y.shape[0]\n            \n    # Getter\n    def __getitem__(self, index):    \n        return self.x[index], self.y[index]\n    \n    # Get Length\n    def __len__(self):\n        return self.len\n    \n    # Plot the diagram\n    def plot_data(self):\n        plt.plot(self.x[self.y[:] == 0, 0].numpy(), self.x[self.y[:] == 0, 1].numpy(), 'o', label=\"y=0\")\n        plt.plot(self.x[self.y[:] == 1, 0].numpy(), self.x[self.y[:] == 1, 1].numpy(), 'ro', label=\"y=1\")\n        plt.plot(self.x[self.y[:] == 2, 0].numpy(),self.x[self.y[:] == 2, 1].numpy(), 'go',label=\"y=2\")\n        plt.legend()"]},{"cell_type":"markdown","id":"49b309b4-472a-4594-af02-343500ee438a","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"f3ead243-1236-49cf-87ae-b32670c4ac95","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Model\"\u003eNeural Network Module and Function for Training\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"a0b7e05f-6cf9-413e-9401-66dba969d60a","metadata":{},"outputs":[],"source":["Create Neural Network Module using \u003ccode\u003eModuleList()\u003c/code\u003e\n"]},{"cell_type":"code","id":"ffee020b-7d12-45ec-96b4-6c73834eb883","metadata":{},"outputs":[],"source":["# Create dataset object\n\nclass Net(nn.Module):\n    \n    # Constructor\n    # Given a list of integers, Layers, we create layers of the neural network where each integer in Layers corresponds to the layers number of neurons\n    def __init__(self, Layers):\n        super(Net, self).__init__()\n        self.hidden = nn.ModuleList()\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            self.hidden.append(nn.Linear(input_size, output_size))\n    \n    # Prediction\n    # Puts the X value through each layer of the neural network while using the RELU activation function in between. The final output is not put through RELU.\n    def forward(self, x):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l \u003c L - 1:\n                x = F.relu(linear_transform(x))    \n            else:\n                x = linear_transform(x)\n        return x"]},{"cell_type":"markdown","id":"66a338d8-5b45-4d09-ac51-3076f05e5470","metadata":{},"outputs":[],"source":["Create the function for training the model.\n"]},{"cell_type":"code","id":"02331cf2-e8e5-4859-8030-89f38689642c","metadata":{},"outputs":[],"source":["# Define the function for training the model\n\ndef train(data_set, model, criterion, train_loader, optimizer, epochs=100):\n    # Lists to keep track of loss and accuracy\n    LOSS = []\n    ACC = []\n    # Number of times we train on the entire dataset\n    for epoch in range(epochs):\n        # For batch in train laoder\n        for x, y in train_loader:\n            # Resets the calculated gradient value, this must be done each time as it accumulates if we do not reset\n            optimizer.zero_grad()\n            # Makes a prediction based on X value\n            yhat = model(x)\n            # Measures the loss between prediction and acutal Y value\n            loss = criterion(yhat, y)\n            # Calculates the gradient value with respect to each weight and bias\n            loss.backward()\n            # Updates the weight and bias according to calculated gradient value\n            optimizer.step()\n        # Saves loss and accuracy\n        LOSS.append(loss.item())\n        ACC.append(accuracy(model,data_set))\n        \n    # Prints the Loss and Accuracy vs Epoch graph\n    results ={\"Loss\":LOSS, \"Accuracy\":ACC}\n    fig, ax1 = plt.subplots()\n    color = 'tab:red'\n    ax1.plot(LOSS,color=color)\n    ax1.set_xlabel('epoch', color=color)\n    ax1.set_ylabel('total loss', color=color)\n    ax1.tick_params(axis = 'y', color=color)\n    \n    ax2 = ax1.twinx()  \n    color = 'tab:blue'\n    ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n    ax2.plot(ACC, color=color)\n    ax2.tick_params(axis='y', color=color)\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    \n    plt.show()\n    return results"]},{"cell_type":"markdown","id":"78db4708-11ab-401d-aba3-b511cf50858c","metadata":{},"outputs":[],"source":["Define a function used to calculate accuracy.\n"]},{"cell_type":"code","id":"678f24ab-b909-445c-b8e5-a2addcca64ef","metadata":{},"outputs":[],"source":["# Define a function for calculating accuracy\n\ndef accuracy(model, data_set):\n    _, yhat = torch.max(model(data_set.x), 1)\n    return (yhat == data_set.y).numpy().mean()"]},{"cell_type":"markdown","id":"20dc9e61-9449-480e-85fa-8ca93b4630be","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"732ccdd9-610a-4dfc-9e1b-3e2fd028e4fb","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Train\"\u003eTrain Different Networks Model different values for the Momentum Parameter\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"96bfebe6-43b3-429d-9676-e0b70e1ea86f","metadata":{},"outputs":[],"source":["Create a dataset object using \u003ccode\u003eData\u003c/code\u003e\n"]},{"cell_type":"code","id":"ebc1f8a8-81ed-4350-bf00-4b3b14bf1f56","metadata":{},"outputs":[],"source":["# Create the dataset and plot it\n\ndata_set = Data()\ndata_set.plot_data()\ndata_set.y = data_set.y.view(-1)"]},{"cell_type":"markdown","id":"24de2a6d-7447-41d4-84e8-b559521f25f2","metadata":{},"outputs":[],"source":["Dictionary to contain different cost and  accuracy values for each epoch  for different values of the momentum parameter.\n"]},{"cell_type":"code","id":"32771876-b3e5-405a-80cb-8f021426834c","metadata":{},"outputs":[],"source":["# Initialize a dictionary to contain the cost and accuracy\n\nResults = {\"momentum 0\": {\"Loss\": 0, \"Accuracy:\": 0}, \"momentum 0.1\": {\"Loss\": 0, \"Accuracy:\": 0}}"]},{"cell_type":"markdown","id":"db030341-5531-4258-a141-72e2bb8af1a9","metadata":{},"outputs":[],"source":["Create a  network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of zero.\n"]},{"cell_type":"code","id":"3e543b56-6a9e-4ca3-a1cf-a3c18e53bfaa","metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons\n\n# Size of input layer is 2, hidden layer is 50, and output layer is 3\n# Our X values are x and y coordinates and this problem has 3 classes\nLayers = [2, 50, 3]\n# Create a model\nmodel = Net(Layers)\nlearning_rate = 0.10\n# Create an optimizer that updates model parameters using the learning rate, gradient, and no momentum\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# Create a Data Loader for the training data with a batch size of 20\ntrain_loader = DataLoader(dataset=data_set, batch_size=20)\n# We create a criterion which will measure loss\ncriterion = nn.CrossEntropyLoss()\n# Use the training function to train the model for 100 epochs\nResults[\"momentum 0\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n# Prints the dataset and decision boundaries\nplot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","id":"88c42a23-6f42-40e6-a443-c6ec3d938f05","metadata":{},"outputs":[],"source":["Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.1.\n","\n","\n"]},{"cell_type":"code","id":"8d0ddab9-687b-41ba-808c-62ad9afff1b2","metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.1 momentum\n\n# Size of input layer is 2, hidden layer is 50, and output layer is 3\n# Our X values are x and y coordinates and this problem has 3 classes\nLayers = [2, 50, 3]\n# Create a model\nmodel = Net(Layers)\nlearning_rate = 0.10\n# Create an optimizer that updates model parameters using the learning rate, gradient, and 0.1 momentum\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.1)\n# Create a Data Loader for the training data with a batch size of 20\ntrain_loader = DataLoader(dataset=data_set, batch_size=20)\n# We create a criterion which will measure loss\ncriterion = nn.CrossEntropyLoss()\n# Use the training function to train the model for 100 epochs\nResults[\"momentum 0.1\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n# Prints the dataset and decision boundaries\nplot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","id":"12502b85-3eb6-4cfb-8ca6-b882009e987d","metadata":{},"outputs":[],"source":["\n","Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.2.\n"]},{"cell_type":"code","id":"f06cb48f-133c-41b0-acf9-c7d90176cc6c","metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.2 momentum\n\n# Size of input layer is 2, hidden layer is 50, and output layer is 3\n# Our X values are x and y coordinates and this problem has 3 classes\nLayers = [2, 50, 3]\n# Create a model\nmodel = Net(Layers)\nlearning_rate = 0.10\n# Create an optimizer that updates model parameters using the learning rate, gradient, and 0.2 momentum\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.2)\n# Create a Data Loader for the training data with a batch size of 20\ntrain_loader = DataLoader(dataset=data_set, batch_size=20)\n# We create a criterion which will measure loss\ncriterion = nn.CrossEntropyLoss()\n# Use the training function to train the model for 100 epochs\nResults[\"momentum 0.2\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n# Prints the dataset and decision boundaries\nplot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","id":"27ee7c79-5aad-4ffe-ab9d-9a73a798ff4d","metadata":{},"outputs":[],"source":["Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.4.\n"]},{"cell_type":"code","id":"9f10da72-36b9-41fa-9787-7a9b92696db8","metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.4 momentum\n\n# Size of input layer is 2, hidden layer is 50, and output layer is 3\n# Our X values are x and y coordinates and this problem has 3 classes\nLayers = [2, 50, 3]\n# Create a model\nmodel = Net(Layers)\nlearning_rate = 0.10\n# Create an optimizer that updates model parameters using the learning rate, gradient, and 0.4 momentum\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.4)\n# Create a Data Loader for the training data with a batch size of 20\ntrain_loader = DataLoader(dataset=data_set, batch_size=20)\n# We create a criterion which will measure loss\ncriterion = nn.CrossEntropyLoss()\n# Use the training function to train the model for 100 epochs\nResults[\"momentum 0.4\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n# Prints the dataset and decision boundaries\nplot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","id":"cf0e481e-2e8b-4844-964a-70b43cc0f59c","metadata":{},"outputs":[],"source":["Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.5.\n"]},{"cell_type":"code","id":"5a25a147-d7f2-4e2f-b589-68888da57b58","metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.5 momentum\n\n# Size of input layer is 2, hidden layer is 50, and output layer is 3\n# Our X values are x and y coordinates and this problem has 3 classes\nLayers = [2, 50, 3]\n# Create a model\nmodel = Net(Layers)\nlearning_rate = 0.10\n# Create an optimizer that updates model parameters using the learning rate, gradient, and 0.5 momentum\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n# Create a Data Loader for the training data with a batch size of 20\ntrain_loader = DataLoader(dataset=data_set, batch_size=20)\n# We create a criterion which will measure loss\ncriterion = nn.CrossEntropyLoss()\n# Use the training function to train the model for 100 epochs\nResults[\"momentum 0.5\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n# Prints the dataset and decision boundaries\nplot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","id":"69868c32-6b8b-4204-9f57-5dcad9081f66","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"83db5ef7-286d-457f-84e9-5eca58dbc665","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Result\"\u003eCompare Results of Different Momentum Terms\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"10740ed1-4db6-49a3-a932-a4ef1b9186c1","metadata":{},"outputs":[],"source":["The plot below compares the results of different momentum terms. We see that in general. The Cost decreases proportionally to the momentum term, but larger momentum terms lead to larger oscillations. While the momentum term decreases faster, it seems that a momentum term of 0.2 reaches the smallest value for the cost. \n"]},{"cell_type":"code","id":"100e21c1-ac6f-4bf0-aed4-60f60bb58954","metadata":{},"outputs":[],"source":["# Plot the Loss result for each term\n\nfor key, value in Results.items():\n    plt.plot(value['Loss'],label=key)\n    plt.legend()\n    plt.xlabel('epoch')\n    plt.ylabel('Total Loss or Cost')"]},{"cell_type":"markdown","id":"10e0b4b0-073a-4777-bca5-25f87820e03b","metadata":{},"outputs":[],"source":["The  accuracy seems to be proportional to the momentum term.\n"]},{"cell_type":"code","id":"58e3ddad-6948-423a-a8c9-021c3b82f026","metadata":{},"outputs":[],"source":["# Plot the Accuracy result for each term\n\nfor key, value in Results.items():\n    plt.plot(value['Accuracy'],label=key)\n    plt.legend()\n    plt.xlabel('epoch')\n    plt.ylabel('Accuracy')"]},{"cell_type":"markdown","id":"7bee579d-c7f1-43ca-96b6-78b65976250c","metadata":{},"outputs":[],"source":["\n","\u003ca href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\u0026context=cpdaas\u0026apps=data_science_experience%2Cwatson_machine_learning\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"4522f47a-0f2b-4b55-b6ae-0748717ba7f1","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"ed7348ac-b7d4-468d-bcb1-de08c3145206","metadata":{},"outputs":[],"source":["\u003ch2\u003eAbout the Authors:\u003c/h2\u003e \n","\n","\u003ca href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\"\u003eJoseph Santarcangelo\u003c/a\u003e has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","id":"2fa7122d-e574-4d8c-800b-7d8e0c610017","metadata":{},"outputs":[],"source":["Other contributors: \u003ca href=\"https://www.linkedin.com/in/michelleccarey/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\"\u003eMichelle Carey\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/jiahui-mavis-zhou-a4537814a?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\"\u003eMavis Zhou\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"037fddf5-2eee-47ae-b750-414bbad09d4a","metadata":{},"outputs":[],"source":["\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n","\n","\n","\u003chr\u003e\n","\n","## \u003ch3 align=\"center\"\u003e Â© IBM Corporation 2020. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}