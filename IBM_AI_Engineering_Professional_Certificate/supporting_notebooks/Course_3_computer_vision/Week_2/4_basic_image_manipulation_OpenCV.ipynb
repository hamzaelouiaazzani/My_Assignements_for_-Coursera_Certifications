{"cells":[{"cell_type":"markdown","metadata":{},"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2022-01-01\" target=\"_blank\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["**\u003ch1\u003e Manipulating Images \u003c/h1\u003e**\n"]},{"cell_type":"markdown","metadata":{},"source":["Estimated time needed: **30** minutes\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003eObjectives\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["In this lab, you will learn how to manipulate images, OpenCV image Arrays. You will learn how to copy an image to avoid aliasing. We will cover flipping images and cropping images. You will also learn to change pixel images; this will allow you to draw shapes, write text and superimpose images over other images.\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003cul\u003e\n","    \u003cli\u003e\u003ca href='#MI'\u003eManipulating Images \u003c/a\u003e\n","        \u003cul\u003e\n","            \u003cli\u003eCopying Images  \u003c/li\u003e\n","            \u003cli\u003eFliping Images \u003c/li\u003e\n","            \u003cli\u003eCropping an Image \u003c/li\u003e\n","            \u003cli\u003eChanging Specific Image Pixels \u003c/li\u003e\n","     \n","  \n","    \n","\u003c/ul\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["----\n"]},{"cell_type":"markdown","metadata":{},"source":["Download the images for the lab\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/cat.png -O cat.png\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/lenna.png -O lenna.png\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/baboon.png -O baboon.png"]},{"cell_type":"markdown","metadata":{},"source":["We will be using these imported functions in the lab\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["## Copying Images\n"]},{"cell_type":"markdown","metadata":{},"source":["If you want to reassign an array to another variable, you should use the `copy` method. If we do not apply the method `copy()`, the variable will point to the same location in memory. Consider the following array:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["baboon = cv2.imread(\"baboon.png\")\n","plt.figure(figsize=(10,10))\n","plt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["If we do not apply the method `copy()`, the new variable will point to the same location in memory:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["A = baboon"]},{"cell_type":"markdown","metadata":{},"source":["we use the `id` function to find the object's memory address; we see it is the same as the original array.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["id(A)==id(baboon)\n","id(A)"]},{"cell_type":"markdown","metadata":{},"source":["If we apply the method `copy()\u003c/coode\u003e, the memory address is different \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["B = baboon.copy()\n","id(B)==id(baboon)"]},{"cell_type":"markdown","metadata":{},"source":["When we do not apply the method \u003ccode\u003ecopy()\u003c/code\u003e, the variable will point to the same location in memory. Consider the array \u003ccode\u003ebaboon\u003c/code\u003e, if we set all its values to zero, then all the values in \u003ccode\u003eA\u003c/code\u003e will be zero. This is because \u003ccode\u003ebaboon\u003c/code\u003e and \u003ccode\u003eA\u003c/code\u003e point to the same place in memory, but \u003ccode\u003eB\u003c/code\u003e will not be affected. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["baboon[:,:,] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.subplot(121)\n","plt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\n","plt.title(\"baboon\")\n","plt.subplot(122)\n","plt.imshow(cv2.cvtColor(A, cv2.COLOR_BGR2RGB))\n","plt.title(\"array A\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We see they are the same, this is called aliasing. Aliasing happens whenever one variable's value is assigned to another variable because variables are just names that store references to values. We can also compare \u003ccode\u003ebaboon\u003c/code\u003e and array \u003ccode\u003eB\u003c/code\u003e:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.subplot(121)\n","plt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\n","plt.title(\"baboon\")\n","plt.subplot(122)\n","plt.imshow(cv2.cvtColor(B, cv2.COLOR_BGR2RGB))\n","plt.title(\"array B\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["\n","They are different because they used the method copy.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Fliping Images \n"]},{"cell_type":"markdown","metadata":{},"source":["Flipping images involves reordering the index of the pixels such that it changes the orientation of the image. Consider the following image:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image = cv2.imread(\"cat.png\")\n","plt.figure(figsize=(10,10))\n","plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We can cast it to an array and find the shape:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["width, height,C=image.shape\n","print('width, height,C',width, height,C)"]},{"cell_type":"markdown","metadata":{},"source":["Let's Flip i.e rotate it vertically. First, we create an array of equal size of type \u003ccode\u003enp.uint8\u003c/code\u003e bit image.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["array_flip = np.zeros((width, height,C),dtype=np.uint8)"]},{"cell_type":"markdown","metadata":{},"source":["We assign the first row of pixels of the original array to the new array's last row. We repeat the process for every row, incrementing the row number for the original array and decreasing the new array's row index assigning the pixels accordingly.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i,row in enumerate(image):\n","        array_flip[width-1-i,:,:]=row"]},{"cell_type":"markdown","metadata":{},"source":["We plot the results\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(5,5))\n","plt.imshow(cv2.cvtColor(array_flip, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["\u003ccode\u003eOpenCV\u003c/code\u003ehas several ways to flip an image, we can use  the \u003ccode\u003eflip()\u003c/code\u003e function; we have the input image array. The parameter is the \u003ccode\u003eflipCode\u003c/code\u003e\n","\n","is the value indicating what kind of flip we would like to perform; \n","\u003cli\u003e\u003ccode\u003eflipcode\u003c/code\u003e = 0: flip vertically around the x-axis\u003c/li\u003e\n","\u003cli\u003e\u003ccode\u003eflipcode\u003c/code\u003e \u003e 0: flip horizontally around y-axis positive value\u003c/li\u003e\n","\u003cli\u003e\u003ccode\u003eflipcode\u003c/code\u003e\u0026#60 0: flip vertically and horizontally, flipping around both axes negative value\u003c/li\u003e\n","Let apply different \u003ccode\u003eflipcode\u003c/code\u003e's in a loop:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for flipcode in [0,1,-1]:\n","    im_flip =  cv2.flip(image,flipcode )\n","    plt.imshow(cv2.cvtColor(im_flip,cv2.COLOR_BGR2RGB))\n","    plt.title(\"flipcode: \"+str(flipcode))\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We can also use the \u003ccode\u003erotate()\u003c/code\u003e function. The parameter is an integer indicating what kind of flip we would like to perform. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["im_flip = cv2.rotate(image,0)\n","plt.imshow(cv2.cvtColor(im_flip,cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["OpenCV module has built-in attributes the describe the type of flip, the values are just integers. Several are shown in the following \u003ccode\u003edict\u003c/code\u003e:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["flip = {\"ROTATE_90_CLOCKWISE\":cv2.ROTATE_90_CLOCKWISE,\"ROTATE_90_COUNTERCLOCKWISE\":cv2.ROTATE_90_COUNTERCLOCKWISE,\"ROTATE_180\":cv2.ROTATE_180}"]},{"cell_type":"markdown","metadata":{},"source":["We see the keys are just an integer\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["flip[\"ROTATE_90_CLOCKWISE\"]"]},{"cell_type":"markdown","metadata":{},"source":["We can plot each of the outputs using the different  parameter values \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key, value in flip.items():\n","    plt.subplot(1,2,1)\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    plt.title(\"orignal\")\n","    plt.subplot(1,2,2)\n","    plt.imshow(cv2.cvtColor(cv2.rotate(image,value), cv2.COLOR_BGR2RGB))\n","    plt.title(key)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":[" ## Cropping an Image\n"]},{"cell_type":"markdown","metadata":{},"source":["Cropping is \"cutting out\" the part of the image and throwing out the rest; we can crop using arrays. Let start with a vertical crop; the variable \u003ccode\u003eupper\u003c/code\u003e is the first row that we would like to include in the image, the variable \u003ccode\u003elower\u003c/code\u003e is the last row we would like to include. We then use slicing to obtain the new image. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["upper = 150\n","lower = 400\n","crop_top = image[upper: lower,:,:]\n","plt.figure(figsize=(10,10))\n","plt.imshow(cv2.cvtColor(crop_top, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["consider the array \u003ccode\u003ecrop_top\u003c/code\u003e we  can also crop horizontally  the variable right is the first column that we would like to include in the image, the variable left is the last column we would like to include in the image.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["left = 150\n","right = 400\n","crop_horizontal = crop_top[: ,left:right,:]\n","plt.figure(figsize=(5,5))\n","plt.imshow(cv2.cvtColor(crop_horizontal, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Changing Specific Image Pixels\n"]},{"cell_type":"markdown","metadata":{},"source":["We can change specific image pixels using  array indexing; for example, we can set  all the channels in the original image we cropped to zero :\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["array_sq = np.copy(image)\n","array_sq[upper:lower,left:right,:] = 0"]},{"cell_type":"markdown","metadata":{},"source":["We can compare the results to the new image. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","plt.subplot(1,2,1)\n","plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n","plt.title(\"orignal\")\n","plt.subplot(1,2,2)\n","plt.imshow(cv2.cvtColor(array_sq,cv2.COLOR_BGR2RGB))\n","plt.title(\"Altered Image\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["  We can also create shapes and \u003ccode\u003eOpenCV\u003c/code\u003e, we can use the method \u003ccode\u003erectangle\u003c/code\u003e. The parameter  \u003ccode\u003ept1\u003c/code\u003e is the top-left coordinate of the rectangle: \u003ccode\u003e(left,top)\u003c/code\u003e or $(x_0,y_0)$, \u003ccode\u003ept2\u003c/code\u003e is the bottom right coordinate\u003ccode\u003e(right,lower)\u003c/code\u003e or $(x_1,y_1)$. The parameter \u003ccode\u003ecolor\u003c/code\u003e  is a tuple representing the intensity of each channel \u003ccode\u003e( blue, green, red)\u003c/code\u003e. Finally, we have the line thickness.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["start_point, end_point = (left, upper),(right, lower)\n","image_draw = np.copy(image)\n","cv2.rectangle(image_draw, pt1=start_point, pt2=end_point, color=(0, 255, 0), thickness=3) \n","plt.figure(figsize=(5,5))\n","plt.imshow(cv2.cvtColor(image_draw, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We can overlay text on an image using the function  \u003ccode\u003eputText\u003c/code\u003e with the following parameter values:\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"," \u003cli\u003e\u003ccode\u003eimg\u003c/code\u003e: Image array \u003c/li\u003e\n","\u003cli\u003e\u003ccode\u003etext\u003c/code\u003e: Text string to be overlayed\u003c/li\u003e\n","\u003cli\u003e\u003ccode\u003eorg\u003c/code\u003e: Bottom-left corner of the text string in the image\u003c/li\u003e\n","\u003cli\u003e\u003ccode\u003efontFace\u003c/code\u003e: tye type of font \u003c/li\u003e\n","\u003cli\u003e\u003ccode\u003efontScale\u003c/code\u003e: Font scale\u003c/li\u003e\n","\u003cli\u003e\u003ccode\u003ecolor\u003c/code\u003e: Text color\u003c/li\u003e\n","\u003cli\u003e\u003ccode\u003ethickness\u003c/code\u003e: Thickness of the lines used to draw a text\u003c/li\u003e\n","\u003cli\u003e\u003ccode\u003elineType:\u003c/code\u003e Line type\u003c/li\u003e\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_draw=cv2.putText(img=image,text='Stuff',org=(10,500),color=(255,255,255),fontFace=4,fontScale=5,thickness=2)\n","plt.figure(figsize=(10,10))\n","plt.imshow(cv2.cvtColor(image_draw,cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Question-4: \n","Use the image baboon.png from this lab or take any image you like.\n","\n","Open the image and create a OpenCV Image object called `im`, convert the image from BGR format to RGB format, flip `im` vertically around the x-axis and create an image called `im_flip`, mirror `im` by flipping it horizontally around the y-axis and create an image called `im_mirror`, finally plot both images\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# write your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["Double-click **here** for a hint.\n","\n","\u003c!-- The hint is below:\n","\n","im_flip =  cv2.flip(baboon,0)\n","im_mirror =  cv2.flip(baboon, 1)\n","\n","--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Double-click **here** for the solution.\n","\n","\u003c!-- The answer is below:\n","\n","im = cv2.imread(\"baboon.png\")\n","\n","im_flip =  cv2.flip(im, 0)\n","plt.imshow(cv2.cvtColor(im_flip, cv2.COLOR_BGR2RGB))\n","plt.show()\n","\n","im_mirror =  cv2.flip(im, 1)\n","plt.imshow(cv2.cvtColor(im_mirror, cv2.COLOR_BGR2RGB))\n","plt.show()\n","\n","--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003eAuthors\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":[" [Joseph Santarcangelo](https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2022-01-01) has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"]},{"cell_type":"markdown","metadata":{},"source":["[Nayef Abou Tayoun](https://www.linkedin.com/in/nayefaboutayoun/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2022-01-01) has a master of management in artificial intelligence degree, focusing on using machine learning and computer vision.\n"]},{"cell_type":"markdown","metadata":{},"source":["# References \n"]},{"cell_type":"markdown","metadata":{},"source":["[1]  Images were taken from: https://homepages.cae.wisc.edu/~ece533/images/\n","    \n","[2]  \u003ca href='https://pillow.readthedocs.io/en/stable/index.html?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2022-01-01'\u003ePillow Docs\u003c/a\u003e\n","\n","[3]  \u003ca href='https://opencv.org/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2022-01-01'\u003eOpen CV\u003c/a\u003e\n","\n","[4] Gonzalez, Rafael C., and Richard E. Woods. \"Digital image processing.\" (2017).\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003eChange Log\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ctable\u003e\n","    \u003ctr\u003e\n","        \u003cth\u003eDate (YYYY-MM-DD)\u003c/th\u003e\n","        \u003cth\u003eVersion\u003c/th\u003e\n","        \u003cth\u003eChanged By\u003c/th\u003e\n","        \u003cth\u003eChange Description\u003c/th\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","        \u003ctd\u003e2020-07-20\u003c/td\u003e\n","        \u003ctd\u003e0.2\u003c/td\u003e\n","        \u003ctd\u003eAzim\u003c/td\u003e\n","        \u003ctd\u003eModified Multiple Areas\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","        \u003ctd\u003e2020-07-17\u003c/td\u003e\n","        \u003ctd\u003e0.1\u003c/td\u003e\n","        \u003ctd\u003eAzim\u003c/td\u003e\n","        \u003ctd\u003eCreated Lab Template\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","        \u003ctd\u003e2021-03-06\u003c/td\u003e\n","        \u003ctd\u003e0.3\u003c/td\u003e\n","        \u003ctd\u003eNayef\u003c/td\u003e\n","        \u003ctd\u003eModified some codes\u003c/td\u003e\n","    \u003c/tr\u003e\n","\u003c/table\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Copyright © 2020 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}